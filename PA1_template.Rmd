# Reproducible Research: Peer Assessment 1
### *Taking a Walk with Data - Jay Gendron*

## Loading and preprocessing the data

The purpose of this analysis is to answer a series of questions relating to the activity patterns of subjects wearing a personal activity monitoring device. The [data][1] (Peng, 2014) for this analysis was provided to us on the Reproducible Research [GitHub repository][2] for the Coursera Data Science Specialization Program. The data used in this analysis is described in the source: 

>This device collects data at 5 minute intervals through out the day. The data consists of two months of data from an anonymous individual collected during the months of October and November, 2012 and include the number of steps taken in 5 minute intervals each day. (Reproducible Research | Coursera, 2014, para. 3)  

Because the data was placed in the GitHub repository, loading the data is a simple matter of unzipping the file and reading in the .csv file into a dataframe using the *read.csv* command.

```{r loaddata}
#Unzip the data and then read into dataframe
unzip("./RepData_PeerAssessment1/activity.zip")
DF<-read.csv("activity.csv") #, colClasses=c(NA,"factor","factor"))
#Present the underlying structure of dataframe DF
str(DF)
```

Based on a review of the analytic needs of the project, an additional dataframe (dataComplete) was generated to isolate only "complete cases" having no missing values. This was accomplished by transforming the original dataframe (DF) using the *complete.cases()* command to remove all rows having an "NA" value. No other transformations were necessary on the original dataframe. specifically, the structure of DF (and dataComplete) are appropriate for this analyis [steps=>int; data=>factor; interval=>int].

```{r elimateMissingValues}
#Eliminate all rows having value "NA"
complete<-complete.cases(DF)
#Generate dataframe with only complete data
dataComplete<-DF[complete,]
```

A summary view of the original and transformed dataframes shows that the 2,304 missing values (observations) were removed with no other impacts on the data. the .

```{r tranformResults}
summary(DF)
summary(dataComplete)
```

The transformed dataframe was reduced from 17,568 observations to 15,264 observations

``` {r sizeofComplete}
str(dataComplete)
```
## What is mean total number of steps taken per day?



For this part of the assignment, you can ignore the missing values in the dataset.
1. Make a histogram of the total number of steps taken each day
2. Calculate and report the mean and median total number of steps taken
per day

``` {r mean per day, fig.width=11,fig.height=4}
sum <-tapply(dataComplete$steps, dataComplete$date, sum, na.rm=TRUE)
means <-tapply(dataComplete$steps, dataComplete$date, mean, na.rm=TRUE)
medians <-tapply(dataComplete$steps, dataComplete$date, median, na.rm=TRUE)
summary(sum)
summary(means)
summary(medians)
hist(sum,breaks=20,main="Figure 1: Total Number of Steps Taken Each Day",
     xlab="Number of Steps Taken")
```

## What is the average daily activity pattern?

1. Make a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all days (y-axis)
2. Which 5-minute interval, on average across all the days in the dataset, contains the maximum number of steps?

```{r timeseries, fig.height=4, fig.width=11}
interval.means <-tapply(dataComplete$steps, dataComplete$interval, mean,na.rm=TRUE)
interval.medians <-tapply(dataComplete$steps, dataComplete$date, median, na.rm=TRUE)
highest<-which(interval.means==max(interval.means))
steps<-interval.means[highest]
interval<-names(steps)
plot(interval.means ~ names(interval.means), type="l", lwd=2, col="blue",
     main="Figure 2: Daily Activity Pattern - Average Steps Taken Across Days",
     xlab="5-Minute Interval Identifier", ylab="Average Number of Steps")
abline(v =interval)
text(interval, max(interval.means)-25, pos=4,
     paste("Most active interval: ",interval), col = "darkgreen")
```

the highest is `r steps` which occurs in interval `r interval` (equivalent to `r substr(interval,nchar(interval)-1,nchar(interval))`

## Imputing missing values

The purpose of this section of the analysis is to investigate the impact of imputing data within a dataset having many missing values. Note that there are a number of days/intervals where there are missing values (coded as NA). The presence of missing days may introduce bias into some calculations or summaries of the data.
1. Calculate and report the total number of missing values in the dataset (i.e. the total number of rows with NAs)

This table call provides an indication of the magnitude of misssing values in the full dataset:

```{r missingValues}
missing<-is.na(DF)
table(missing)
```

As noted in the assignment instructions, a dataset containing a large number of missing values could introduce bias into the results for daily activity patterns. These missing value can be filled with generated data using a process called imputation. This process requires a strategy. The assignment asked us to developed a relatively simplistic approach to imputation. Based on the work we have thusfar, let's consider how representative the various means and medians for days and intervals from values already calculated.

2. Devise a strategy for filling in all of the missing values in the dataset. The strategy does not need to be sophisticated. For example, you could use the mean/median for that day, or the mean for that 5-minute interval, etc.A

``` {r imputationStrategy,fig.height=4,fig.width=11}
boxplot(means,medians,interval.means,interval.medians,axes=FALSE,
	main="Figure 3: Consideration of data distribution for imputation  strategy",
	xlab="Measures of center and spread by two perspectives",
	ylab="Average Steps")
axis(1, 1:4, c("Mean by day","Median by day","Mean by interval",
	"Median by interval"))
axis(2)
box()
```

Based on this quick boxplot, one may dismiss a strategy using the data factored by interval as compared by day based on the higher variance present. This makes sense in light of the time series plot of daily activity patterns in Figure 2 showing the variation seen with respect to time of day. That leaves manipulation by day. It is noteworthy to see a median of zero. This indicates a very right-skewed dataset. In these cases, a more robust measure of center is median; however, simply adding a value of "0" for each step observation of "NA" would not enhance the data - it would yield the same results.

This led to an inquiry on other methods of imputation that may *blend* the final dataset with a combination of "0"s and "NA"s that are representative of the data collected.

Kabucoff (2011) notes, "In simple imputation, the missing values in a variable are replaced with a single value (for example, mean, median, or mode)...An advantage to simple imputation is that it solves the 'missing values problem' without reducing the sample size" (p. 371).

However, the author forewarns readers by noting, "...simple imputation is likely to underestimate standard errors, distort correlations among variables, and produce incorrect p-values in statistical tests. Like pairwise deletion, I recommend avoiding this approach for most missing data problems" (p. 371).

3. Create a new dataset that is equal to the original dataset but with the missing data filled in.

``` {r imputation using mice package,cache=TRUE}
if (!"mice" %in% installed.packages()) {install.packages("mice")}
library(mice)
imp <- mice(DF, m=2) # runs steps per iteration
fit <- with(imp, lm(steps ~ date + interval)) #runs 5 iterations 
pooled <- pool(fit)
#summary(pooled)   #available but not run here. See CRAN documentation
#Merges original data (DF) with imputed date
finaldata <- complete(imp, 1)
dim(imp$imp$steps)
```

A quick summary look at this imputed data shows no missing data
``` {r imputed data}
summary(finaldata)
```

Summary of original data
``` {r original data}
summary(DF)
```

``` {r, echo=FALSE}
orig=summary(DF)
new=summary(finaldata)
```

As compared with a summary of the original data, the adjusted `r new[4,1]` differs only slightly from the original `r orig[4,1]` 


4. Make a histogram of the total number of steps taken each day and Calculate and report the mean and median total number of steps taken per day. 

``` {r UpdatedHistogram-MeanPerDay, fig.width=11,fig.height=4}
sum.full <-tapply(finaldata$steps, finaldata$date, sum, na.rm=TRUE)
means.full <-tapply(dataComplete$steps, dataComplete$date, mean, na.rm=TRUE)
medians.full <-tapply(dataComplete$steps, dataComplete$date, median, na.rm=TRUE)
summary(sum.full)
summary(means.full)
summary(medians.full)
hist(sum.full,breaks=20)
```

The assignment posed the question, **Do these values differ from the estimates from the first part of the assignment?**

The assignment also posed the question, **What is the impact of imputing missing data on the estimates of the total daily number of steps?**

## Are there differences in activity patterns between weekdays and weekends?

For this part the weekdays() function may be of some help here. Use the dataset with the filled-in missing values for this part.

``` {r isolate weekends}
finaldata.dates<-as.Date(finaldata[,2])
weekdays<-weekdays(finaldata.dates)
finaldata<-cbind(finaldata,weekdays)
finaldata$weekdays<-gsub("Sunday","weekend",finaldata$weekdays)
finaldata$weekdays<-gsub("Saturday","weekend",finaldata$weekdays)
finaldata$weekdays<-gsub(".*day?","weekday",finaldata$weekdays)
```

1. Create a new factor variable in the dataset with two levels – “weekday” and “weekend” indicating whether a given date is a weekday or weekend day.
2. Make a panel plot containing a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all weekday days or weekend days (y-axis). 

``` {r lattice plot of weekday vs. weekend}
library(lattice)
## Simple scatterplot
interval.means.full <-tapply(finaldata$steps,
	INDEX=list(finaldata$interval,finaldata$weekdays),
	mean,na.rm=TRUE)
head(interval.means.full)
```

#xyplot(Ozone ~ Wind | weekdays, data = finaldata, layout = c(1,2))


```{r employ reshape2 to melt data}
library(reshape2)
md <- melt(interval.means.full)
names(md)
```

Now we can easily plot it with the `xyplot()` function to compare the activity patterns:

```{r, fig.height=8, fig.width=10} 
library(lattice)
xyplot(value ~ Var1 | Var2, data = md, type="l",layout=c(1,2),
       xlab="Interval",ylab="Average number of steps",
       main="blah blah blah")
```

<!-- URL List -->
[1]: https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip
[2]: http://github.com/rdpeng/RepData_PeerAssessment1

### References

Peng, R. D. (2014, February 11). Activity monitoring data [Data file]. Retrieved from http://github.com/rdpeng/RepData_PeerAssessment1.

Reproducible Research | Coursera. (2014). *Peer Assessment 1*. Retrieved from https://class.coursera.org/repdata-002/human_grading/view/courses/972084/assessments/3/submissions.


van Buuren, S., Groothuis-Oudshoorn, K., Robitzsch, A., Vink, G., Doove, L., & Jolani, S. (2014, February 5). *Multivariate imputation by chained equations*. Retrieved from http://cran.r-project.org/web/packages/mice/mice.pdf.



URL http://www.stefvanbuuren.nl , http://www.multiple-imputation.com






